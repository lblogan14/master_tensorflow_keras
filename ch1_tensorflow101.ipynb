{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch1_tensorflow101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/master_tensorflow_keras/blob/master/ch1_tensorflow101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4AEbyexTGnGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Models of the TensorFlow:\n",
        "* **data model**, consisting of tensors\n",
        "* **programming model**, consisting of data flow graphs or computation graphs\n",
        "* **execution mode**l, consisting of firing the nodes in a sequence based on the dependence conditions, starting from the initial nodes that depend on inputs"
      ]
    },
    {
      "metadata": {
        "id": "CFeRgl9IHPgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **lower-level library**, also known as TensorFlow core,\n",
        "provides very fine-grained lower level functionality, thereby offering complete\n",
        "control on how to use and implement the library in the models.\n",
        "* **higher-level library**, provides high-level functionalities and are\n",
        "comparatively easier to learn and implement in the models. Some of the libraries\n",
        "include TF Estimators, TFLearn, TFSlim, Sonnet, and Keras."
      ]
    },
    {
      "metadata": {
        "id": "lT99ybz1HvzC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TensorFlow core\n",
        "## Code warm up - Hello TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "pMLZFnCLIHZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVuGvACcIWOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfs = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7MYNUaFINRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow offers two kinds of sessions: **Session()** and **InteractiveSession()**.\n",
        "\n",
        "The session created with **InteractiveSession()** becomes the default session. Thus, we do not need to specify the session context to\n",
        "execute the session-related command later. \n",
        "\n",
        "For example, say that we have a session object, **tfs**, and a constant object, **hello**. If tfs is an **InteractiveSession()** object, then we can evaluate hello with the code **hello.eval()**. If **tfs** is a **Session()** object, then we have to use either **tfs.hello.eval()** or a **with** block. The most common practice is to use the **with** block."
      ]
    },
    {
      "metadata": {
        "id": "YP8rrHepI8Zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1e4204e-b70c-44ec-ddea-82ca5e5c55ee"
      },
      "cell_type": "code",
      "source": [
        "hello = tf.constant('Hello TensorFlow !!')\n",
        "print(tfs.run(hello))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TensorFlow !!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAlF19p7JHuH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Tensors,\n",
        "is an n-dimensional collection of data, identified by rank, shape, and type.\n",
        "* *rank*, number of dimensions of a tensor\n",
        "* *shape*, a list denoting a size in each dimension\n",
        "* *type*, data type"
      ]
    },
    {
      "metadata": {
        "id": "A4e74MVoKQk2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Constants\n",
        "    tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)"
      ]
    },
    {
      "metadata": {
        "id": "mBtacQiQKdJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c1=tf.constant(5,name='x')\n",
        "c2=tf.constant(6.0,name='y')\n",
        "c3=tf.constant(7.0,tf.float32,name='z')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMfEdNwfKrQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b23648dd-e356-4e3a-ae72-ff803baddb53"
      },
      "cell_type": "code",
      "source": [
        "print('c1 (x): ',c1)\n",
        "print('c2 (y): ',c2)\n",
        "print('c3 (z): ',c3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c1 (x):  Tensor(\"x:0\", shape=(), dtype=int32)\n",
            "c2 (y):  Tensor(\"y:0\", shape=(), dtype=float32)\n",
            "c3 (z):  Tensor(\"z:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7r2FzZypKzCN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to print the values of these constants, we have to execute them in a TensorFlow\n",
        "session with the **tfs.run()** command:"
      ]
    },
    {
      "metadata": {
        "id": "AXp_zz9PK1bK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5d26fe1-548e-400e-883b-9ab374b54189"
      },
      "cell_type": "code",
      "source": [
        "print('run([c1, c2, c3]) : ', tfs.run([c1, c2, c3]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run([c1, c2, c3]) :  [5, 6.0, 7.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5t7prFyRLAKw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Operations"
      ]
    },
    {
      "metadata": {
        "id": "mPpjpkfHLEiZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "op1 = tf.add(c2, c3)\n",
        "op2 = tf.multiply(c2, c3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NLOPJOzKLIah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8a3c5c59-2a82-4e6c-8556-5a2955f66718"
      },
      "cell_type": "code",
      "source": [
        "print('op1 : ', op1)\n",
        "print('op2 : ', op2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "op1 :  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
            "op2 :  Tensor(\"Mul:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2zOJELJCLO0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To print the value of these operations, we have to run them in our TensorFlow session:"
      ]
    },
    {
      "metadata": {
        "id": "gD-O5KLkLMVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edaace25-186a-4b0a-83f0-b4caf7ccd11d"
      },
      "cell_type": "code",
      "source": [
        "print('run(op1) : ', tfs.run(op1))\n",
        "print('run(op2) : ', tfs.run(op2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(op1) :  13.0\n",
            "run(op2) :  42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zLXn7ptRLbih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "built-in operations,\n",
        "* Arithmetic,\n",
        "    \n",
        "    `tf.add, tf.subtract, tf.multiply, tf.scalar_mul, tf.div, tf.divide, tf.truediv, tf.floordiv, tf.realdiv, tf.truncatediv, tf.floor_div, tf.truncatemod, tf.floormod, tf.mod, tf.cross`\n",
        "* Basic math,\n",
        "\n",
        "    `tf.add_n, tf.abs, tf.negative, tf.sign, tf.reciprocal,\n",
        "tf.square, tf.round, tf.sqrt, tf.rsqrt, tf.pow, tf.exp, tf.expm1,\n",
        "tf.log, tf.log1p, tf.ceil, tf.floor, tf.maximum, tf.minimum,\n",
        "tf.cos, tf.sin, tf.lbeta, tf.tan, tf.acos, tf.asin, tf.atan,\n",
        "tf.lgamma, tf.digamma, tf.erf,\n",
        "tf.erfc, tf.igamma, tf.squared_difference, tf.igammac, tf.zeta,\n",
        "tf.polygamma, tf.betainc, tf.rint`\n",
        "\n",
        "* Matrix math,\n",
        "\n",
        "    `tf.diag, tf.diag_part, tf.trace,\n",
        "tf.transpose, tf.eye, tf.matrix_diag, tf.matrix_diag_part,\n",
        "tf.matrix_band_part, tf.matrix_set_diag, tf.matrix_transpose,\n",
        "tf.matmul, tf.norm, tf.matrix_determinant, tf.matrix_inverse,\n",
        "tf.cholesky, tf.cholesky_solve, tf.matrix_solve,\n",
        "tf.matrix_triangular_solve, tf.matrix_solve_ls, tf.qr,\n",
        "tf.self_adjoint_eig, tf.self_adjoint_eigvals, tf.svd`\n",
        "\n",
        "* Tensor math,\n",
        "\n",
        "    `tf.tensordot`\n",
        "    \n",
        "* Complex number,\n",
        "    \n",
        "    `tf.complex, tf.conj, tf.imag, tf.real`\n",
        "    \n",
        "* String,\n",
        "\n",
        "    `tf.string_to_hash_bucket_fast, tf.string_to_hash_bucket_strong,\n",
        "tf.as_string, tf.encode_base64, tf.decode_base64,\n",
        "tf.reduce_join, tf.string_join, tf.string_split, tf.substr,\n",
        "tf.string_to_hash_bucket`"
      ]
    },
    {
      "metadata": {
        "id": "9b1MYSciMRgT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Placeholders\n",
        "allow to create tensors whose values can be provided at runtime.\n",
        "\n",
        "`tf.placeholder(dtype, shape=None, name=None)`"
      ]
    },
    {
      "metadata": {
        "id": "j1QVJHkhMiPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d1016cc2-e2c4-49ab-99d5-f32c310d5d9c"
      },
      "cell_type": "code",
      "source": [
        "p1 = tf.placeholder(tf.float32)\n",
        "p2 = tf.placeholder(tf.float32)\n",
        "print('p1 : ', p1)\n",
        "print('p2 : ', p2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p1 :  Tensor(\"Placeholder:0\", dtype=float32)\n",
            "p2 :  Tensor(\"Placeholder_1:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFKCvi_GMtA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "op4 = p1 * p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rmscJOoM0LY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`p1 * p2` is shorthand for `tf.multiply(p1,p2)`:"
      ]
    },
    {
      "metadata": {
        "id": "xrm7-gYfM8Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8044364-4466-4d8e-9449-4996a825a7ee"
      },
      "cell_type": "code",
      "source": [
        "print('run(op4, {p1:2.0, p2:3.0}) : ', tfs.run(op4, {p1:2.0, p2:3.0}))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(op4, {p1:2.0, p2:3.0}) :  6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hyrWii2QNJHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "or you can specify the dictionary using the `feed_dict` parameter,"
      ]
    },
    {
      "metadata": {
        "id": "hszmL_M5NP5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bf278a2-7df9-4185-c198-187b839809dd"
      },
      "cell_type": "code",
      "source": [
        "print('run(op4, feed_dict={p1:3.0, p2:4.0})) : ',\n",
        "     tfs.run(op4, feed_dict={p1:3.0, p2:4.0}))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(op4, feed_dict={p1:3.0, p2:4.0})) :  12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l8f7NyrJNkAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bce50bb-9cd9-4fd5-b8a6-1229c2f5d93a"
      },
      "cell_type": "code",
      "source": [
        "print('run(op4,feed_dict = {p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}) : ',\n",
        "tfs.run(op4,feed_dict = {p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}))\n",
        "# element-wise"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(op4,feed_dict = {p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}) :  [ 6. 12. 20.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PNpGYrfwNr-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Creating tensors from Python objects\n",
        "`tf.convert_to_tensor(value, dtype=None, name=None, preferred_dtype = None)`\n",
        "\n",
        "`tf.convert_to_tensor()` creates tensors from Python objects"
      ]
    },
    {
      "metadata": {
        "id": "SjRmhadUPvu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "0-D tensor,"
      ]
    },
    {
      "metadata": {
        "id": "m1agozwkPxf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a23d0c77-3c21-4229-85d2-eaf085cbb3e9"
      },
      "cell_type": "code",
      "source": [
        "tf_t = tf.convert_to_tensor(5.0, dtype=tf.float64)\n",
        "print('tf_t : ', tf_t)\n",
        "print('run(tf_t) : ', tfs.run(tf_t))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf_t :  Tensor(\"Const_1:0\", shape=(), dtype=float64)\n",
            "run(tf_t) :  5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rPHmJ8CP_vT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1-D tensor,"
      ]
    },
    {
      "metadata": {
        "id": "w8jx6fccQA_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cf4e674-5952-4fa1-f172-54ec014d2bb5"
      },
      "cell_type": "code",
      "source": [
        "a1dim = np.array([1,2,3,4,5.99])\n",
        "print('a1dim Shape : ', a1dim.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a1dim Shape :  (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eSpT8-RMQJJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf_t = tf.convert_to_tensor(a1dim, dtype=tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFcL4GX1QYpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "839d0960-1531-4ffb-99f4-767b4ea31b76"
      },
      "cell_type": "code",
      "source": [
        "print('tf_t : ', tf_t)\n",
        "print('tf_t[0] : ', tf_t[0])\n",
        "print('tf_t[2] : ', tf_t[2])\n",
        "print('run(tf_t) : \\n', tfs.run(tf_t))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf_t :  Tensor(\"Const_2:0\", shape=(5,), dtype=float64)\n",
            "tf_t[0] :  Tensor(\"strided_slice:0\", shape=(), dtype=float64)\n",
            "tf_t[2] :  Tensor(\"strided_slice_1:0\", shape=(), dtype=float64)\n",
            "run(tf_t) : \n",
            " [1.   2.   3.   4.   5.99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C30uaXCrQzBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2-D tensor,"
      ]
    },
    {
      "metadata": {
        "id": "ytCrnV1ZQ0Zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8ea095b-d5eb-4904-84dc-ea02f66c9687"
      },
      "cell_type": "code",
      "source": [
        "a2dim = np.array([(1,2,3,4,5.99),\n",
        "                  (2,3,4,5,6.99),\n",
        "                  (3,4,5,6,7.99)\n",
        "])\n",
        "print(\"a2dim Shape : \",a2dim.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a2dim Shape :  (3, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fXm48PeNQ820",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf_t = tf.convert_to_tensor(a2dim, dtype=tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3qieyunRAqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e7ceb380-625f-4e57-a489-d6272a431e39"
      },
      "cell_type": "code",
      "source": [
        "print('tf_t : ',tf_t)\n",
        "print('tf_t[0][0] : ',tf_t[0][0])\n",
        "print('tf_t[1][2] : ',tf_t[1][2])\n",
        "print('run(tf_t) : \\n',tfs.run(tf_t))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf_t :  Tensor(\"Const_3:0\", shape=(3, 5), dtype=float64)\n",
            "tf_t[0][0] :  Tensor(\"strided_slice_3:0\", shape=(), dtype=float64)\n",
            "tf_t[1][2] :  Tensor(\"strided_slice_5:0\", shape=(), dtype=float64)\n",
            "run(tf_t) : \n",
            " [[1.   2.   3.   4.   5.99]\n",
            " [2.   3.   4.   5.   6.99]\n",
            " [3.   4.   5.   6.   7.99]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0lmkGc_cRDG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3-D tensor,"
      ]
    },
    {
      "metadata": {
        "id": "RPigiEagREr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcd2306e-ed08-4321-ee2a-0d1028922fa0"
      },
      "cell_type": "code",
      "source": [
        "a3dim = np.array([[[1,2],[3,4]],\n",
        "                  [[5,6],[7,8]]\n",
        "])\n",
        "print(\"a3dim Shape : \",a3dim.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a3dim Shape :  (2, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DgLMWygRLjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cbf47c8c-7a32-44b6-b1b7-d6a0f316d788"
      },
      "cell_type": "code",
      "source": [
        "tf_t=tf.convert_to_tensor(a3dim,dtype=tf.float64)\n",
        "print('tf_t : ',tf_t)\n",
        "print('tf_t[0][0][0] : ',tf_t[0][0][0])\n",
        "print('tf_t[1][1][1] : ',tf_t[1][1][1])\n",
        "print('run(tf_t) : \\n',tfs.run(tf_t))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf_t :  Tensor(\"Const_4:0\", shape=(2, 2, 2), dtype=float64)\n",
            "tf_t[0][0][0] :  Tensor(\"strided_slice_8:0\", shape=(), dtype=float64)\n",
            "tf_t[1][1][1] :  Tensor(\"strided_slice_11:0\", shape=(), dtype=float64)\n",
            "run(tf_t) : \n",
            " [[[1. 2.]\n",
            "  [3. 4.]]\n",
            "\n",
            " [[5. 6.]\n",
            "  [7. 8.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Wliq1NsRPk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Variables\n",
        "`tf.Variable`\n",
        "\n",
        "`tf.placeholder` | `tf.Variable`\n",
        "--- | ---\n",
        "`tf.placeholder` defines input data that does not change over time | `tf.Variable` defines variable values that are modified over time\n",
        "`tf.placeholder` does not need an initial value at the time of definition | `tf.Variable` needs an initial value at the time of definition\n",
        "\n",
        "For a simple linear model\n",
        "$$y=W \\times x + b$$\n",
        "define model parameters as variables with initial values of `[0.3]` and `[-0.3]`"
      ]
    },
    {
      "metadata": {
        "id": "xj_hLboXSI8k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = tf.Variable([0.3], tf.float32)\n",
        "b = tf.Variable([-0.3], tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aE-e1X8LSTC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32)\n",
        "y = w * x + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mczL1qmXSWfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4cdce8ff-4e4e-4850-c1bf-00ca8db489f3"
      },
      "cell_type": "code",
      "source": [
        "print(\"w:\",w)\n",
        "print(\"x:\",x)\n",
        "print(\"b:\",b)\n",
        "print(\"y:\",y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w: <tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n",
            "x: Tensor(\"Placeholder_2:0\", dtype=float32)\n",
            "b: <tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n",
            "y: Tensor(\"add_1:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WMhPw0SdSfxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before you can use the variables in a TensorFlow session, they have to be initialized."
      ]
    },
    {
      "metadata": {
        "id": "2wH5uBpcSgkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfs.run(w.initializer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VwCIChISj-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Or you can try,"
      ]
    },
    {
      "metadata": {
        "id": "P11yKmk7SlGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfs.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEJyaGTxS0Tz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is equivalent to `tf.global_varaibles_initializer().run()`"
      ]
    },
    {
      "metadata": {
        "id": "460KaIxnSrQN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can also use the `tf.variables_initializer()` function to\n",
        "initialize only a set of variables.\n",
        "\n",
        "Now run the model,"
      ]
    },
    {
      "metadata": {
        "id": "YojlCT9DS_h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "672f0eb4-7194-4b6e-b2da-384f26b366c8"
      },
      "cell_type": "code",
      "source": [
        "print('run(y, {x:[1,2,3,4]}) : ', tfs.run(y, {x:[1,2,3,4]}))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(y, {x:[1,2,3,4]}) :  [0.         0.3        0.6        0.90000004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kWyncOS6TcK0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Tensors generated from library functions"
      ]
    },
    {
      "metadata": {
        "id": "f1JINxncT3I7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fcf58d30-8db4-429b-ddb7-0c9b12e23f4d"
      },
      "cell_type": "code",
      "source": [
        "a = tf.zeros((100,))\n",
        "print(tfs.run(a))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l6_r1qzoT9y4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow provides different types of functions to populate the tensors at the time of their\n",
        "definition:\n",
        "* Populating all elements with the same values\n",
        "* Populating elements with sequences\n",
        "* Populating elements with a random probability distribution, such as the normal\n",
        "distribution or the uniform distribution"
      ]
    },
    {
      "metadata": {
        "id": "ewOiFBiYUDuT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Populating tensor elements with the same values\n",
        "* `zeros(shape, dtype=tf.float32, name=None)`, creates a tensor of the provided shape, with all elements set to\n",
        "zero\n",
        "* `zeros_like(tensor, dtype=None, name=None, optimize=True)`, creates a tensor of the same shape as the argument, with all\n",
        "elements set\n",
        "* `ones(shape, dtype=tf.float32, name=None)`, creates a tensor of the provided shape, with all elements set to\n",
        "one\n",
        "* `ones_like(tensor, dtype=None, name=None, optimize=True)`,  creates a tensor of the same shape as the argument, with all\n",
        "elements set to one\n",
        "* `fill(dims, value, name=None)`, creates a tensor of the shape as the `dims` argument, with all elements set to `value`; for example, `a = tf.fill([100],0)`"
      ]
    },
    {
      "metadata": {
        "id": "CwMbJtecU3pq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Populating tensor elements with sequences\n",
        "* `lin_space(start, stop, num, name=None)`, generates a 1-D tensor from a sequence of num numbers within the\n",
        "range `[start, stop]`. The tensor has the same data type as the `start` argument.\n",
        "* `range(limit, delta=1, dtype=None, name='range')`\n",
        "* `range(start, limit, delta=1, dtype=None, name='range')`, generates a 1-D tensor from a sequence of numbers within the range `[start, limit]`, with the increments of `delta`. If the `dtype` argument is not specified, then the tensor has the same data type as the `start` argument. This function comes in two versions. In the second version, if the `start` argument is omitted, then `start` becomes number 0."
      ]
    },
    {
      "metadata": {
        "id": "BD3FSiDBVnWY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Populating tensor elements with a random distribution\n",
        "The distributions generated are affected by the graph-level or the operation-level seed. \n",
        "* The graph-level seed is set using `tf.set_random_seed`\n",
        "* The operation-level seed is given as the argument `seed` in all of the random distribution functions. If no seed is specified,\n",
        "then a random seed is used.\n",
        "\n",
        "* `random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`, generates a tensor of the specified shape, filled with values from a normal distribution: `normal(mean, stddev)`.\n",
        "* `truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`, generates a tensor of the specified shape, filled with values from a truncated normal distribution: `normal(mean, stddev)`. Truncated means that the values returned are always at a distance less than two standard deviations from the mean.\n",
        "* `random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)`, generates a tensor of the specified shape, filled with values from a uniform distribution: `uniform([minval, maxval))`.\n",
        "* `random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)`, generates tensors of the specified shape, filled with values from gamma distributions: `gamma(alpha,beta)`."
      ]
    },
    {
      "metadata": {
        "id": "3sT7moBHW6cJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Getting Variables with `tf.get_variable()`\n",
        "If you define a variable with a name that has been defined before, then TensorFlow throws\n",
        "an exception. Hence, it is convenient to use the `tf.get_variable()` function instead of\n",
        "`tf.Variable()`.\n",
        "\n",
        "`tf.get_variable()` returns the existing variable with the\n",
        "same name if it exists, and creates the variable with the specified shape and initializer if it\n",
        "does not exist."
      ]
    },
    {
      "metadata": {
        "id": "nN95g49VXUP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = tf.get_variable(name='w',shape=[1],dtype=tf.float32,initializer=[.3])\n",
        "b = tf.get_variable(name='b',shape=[1],dtype=tf.float32,initializer=[-.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stw23D50XhN6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The initializer can be a tensor or list of values as shown in above examples or one of the\n",
        "inbuilt initializers:\n",
        "* `tf.constant_initializer`\n",
        "*  `tf.random_normal_initializer`\n",
        "* `tf.truncated_normal_initializer`\n",
        "* `tf.random_uniform_initializer`\n",
        "* `tf.uniform_unit_scaling_initializer`\n",
        "* `tf.zeros_initializer`\n",
        "* `tf.ones_initializer`\n",
        "* `tf.orthogonal_initializer`"
      ]
    },
    {
      "metadata": {
        "id": "2TLtQVvYX6IM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In distributed TensorFlow where we can run the code across machines, the\n",
        "`tf.get_variable()` gives us global variables. Use `tf.get_local_variable()` instead\n",
        "\n",
        "**Sharing or Reusing Variables**: Getting already-defined variables promotes reuse.\n",
        "However, an exception will be thrown if the reuse flags are not set by using\n",
        "`tf.variable_scope.reuse_variable()` or `tf.variable.scope(reuse=True)`."
      ]
    },
    {
      "metadata": {
        "id": "GlLhwPVeYNll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data flow graph or computation graph\n",
        "Each node represents an operation (`tf.Operation`) and each\n",
        "edge represents a tensor (`tf.Tensor`) that gets transferred between the nodes.\n",
        "\n",
        "The TensorFlow comes with a default graph. Unless another graph is explicitly specified, a\n",
        "new node gets implicitly added to the default graph. Access to the default graph:\n",
        "\n",
        "`graph = tf.get_default_graph()`\n",
        "\n",
        "As we create the variables, constants, and placeholders, they get added to the graph. Then\n",
        "we create a `session` object to *execute* the operation objects and *evaluate* the tensor objects."
      ]
    },
    {
      "metadata": {
        "id": "_v5kNHtVZOnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Close the interactive session\n",
        "tfs.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEUHH5EZZRif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Assume Linear model y = w * x + b\n",
        "# model parameters\n",
        "w = tf.Variable([0.3], tf.float32)\n",
        "b = tf.Variable([-0.3], tf.float32)\n",
        "# input/output\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = w * x + b\n",
        "ouput = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xpAbmGKZobV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating and using a session in the `with` block ensures that the session is automatically\n",
        "closed when the block is finished. Otherwise, the session has to be explicitly closed with\n",
        "the `tfs.close()` command, where `tfs` is the session name."
      ]
    },
    {
      "metadata": {
        "id": "eGwipYFUZvKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8938e2ac-7b44-4687-f9c8-f08964a3ddaa"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as tfs:\n",
        "  # initiailze and print the variable y\n",
        "  tf.global_variables_initializer().run()\n",
        "  output = tfs.run(y, {x:[1,2,3,4]})\n",
        "print('output: ', output)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output:  [0.         0.3        0.6        0.90000004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ag1QWzFaHbi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Order of execution and lazy loading\n",
        "lazy loading: the mode objects are not created and initialized until they are needed.\n",
        "\n",
        "Use `tf.Graph.control_dependencies()` to control the order in which the nodes are executed in a graph. For example, if the graph has nodes *a, b, c,* and *d* and you want to execute *c* and *d* before *a* and *b*,\n",
        "\n",
        "    with graph_variable.control_dependencies([c,d]):\n",
        "    # other statements here"
      ]
    },
    {
      "metadata": {
        "id": "i3fkerBBa2-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Executing graphs across compute devices - CPU and GPGPU\n",
        "list all the devices available for graph\n",
        "execution:"
      ]
    },
    {
      "metadata": {
        "id": "rFAs7R2tbFHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "024a5898-4f43-40b0-ed26-3e011590a73c"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 7729484318663983585\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 13340031353424798827\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VXajETkkbes8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When TensorFlow starts executing graphs, it runs the independent paths\n",
        "within each graph in a separate thread, with each thread running on a separate CPU. We\n",
        "can restrict the number of threads used for this purpose by changing the number\n",
        "of `inter_op_parallelism_threads`.\n",
        "\n",
        "inter_op_parallelism_threads. Similarly, if within an independent path, an\n",
        "operation is capable of running on multiple threads, TensorFlow will launch that specific\n",
        "operation on multiple threads. The number of threads in this pool can be changed by setting\n",
        "the number of `intra_op_parallelism_threads`."
      ]
    },
    {
      "metadata": {
        "id": "V1QvEaRfb1R0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Placing graph nodes on specific compute devices\n",
        "Let us enable the logging of variable placement by defining a config object, set the\n",
        "`log_device_placement` property to `true`, and then pass this `config` object to the session\n",
        "as follows:"
      ]
    },
    {
      "metadata": {
        "id": "LHXPY1cWcDM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b668512-9563-4d73-9e54-79e9555a94a7"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# model parameters\n",
        "w = tf.Variable([0.3], tf.float32)\n",
        "b = tf.Variable([-0.3], tf.float32)\n",
        "# input/output\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = w * x + b\n",
        "\n",
        "# add logging here\n",
        "config = tf.ConfigProto()\n",
        "config.log_device_placement = True\n",
        "\n",
        "with tf.Session(config=config) as tfs:\n",
        "  tfs.run(tf.global_variables_initializer())\n",
        "  print('output', tfs.run(y, {x:[1,2,3,4]}))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [0.         0.3        0.6        0.90000004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEkZs0RldXTS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The variables and operations can be placed on\n",
        "specific devices by using `tf.device()` function."
      ]
    },
    {
      "metadata": {
        "id": "0VA8qldndLVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f1194f7-7570-41d4-b359-2235671e0d8e"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.device('/device:CPU:0'):\n",
        "  w = tf.get_variable(name='w', initializer=[0.3], dtype=tf.float32)\n",
        "  b = tf.get_variable(name='b', initializer=[-0.3], dtype=tf.float32)\n",
        "  x = tf.placeholder(name='x', dtype=tf.float32)\n",
        "  y = w * x + b\n",
        "  \n",
        "config = tf.ConfigProto()\n",
        "config.log_device_placement = True\n",
        "\n",
        "with tf.Session(config=config) as tfs:\n",
        "  tfs.run(tf.global_variables_initializer())\n",
        "  print('output', tfs.run(y, {x:[1,2,3,4]}))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [0.         0.3        0.6        0.90000004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-zsAqM0kfbpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.device('/device:CPU:0'):\n",
        "    # Define model parameters\n",
        "    w = tf.get_variable(name='w', initializer=[.3], dtype=tf.float32)\n",
        "    b = tf.get_variable(name='b', initializer=[-.3], dtype=tf.float32)\n",
        "    # Define model input and output\n",
        "    x = tf.placeholder(name='x', dtype=tf.float32)\n",
        "with tf.device('/device:GPU:0'):\n",
        "    y = w * x + b\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.log_device_placement = True\n",
        "\n",
        "with tf.Session(config=config) as tfs:\n",
        "    # initialize and print the variable y\n",
        "    tfs.run(tf.global_variables_initializer())\n",
        "    print('output', tfs.run(y, {x: [1, 2, 3, 4]}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oT3MAyV1eRqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##GPU memory handling\n",
        "* For multi-GPU systems, set the environment variable \n",
        "    \n",
        "    `CUDA_VISIBLE_DEVICES=<list of device idx>`\n",
        "    \n",
        "    `os.environ['CUDA_VISIBLE_DEVICES']='0'`\n",
        "    \n",
        "* When you do not want the session to grab all of the memory of the GPU, then\n",
        "you can use the config option `per_process_gpu_memory_fraction` to allocate\n",
        "a percentage of memory:\n",
        "\n",
        "    `config.gpu_options.per_process_gpu_memory_fraction = 0.5`\n",
        "    \n",
        "* You can also limit the TensorFlow process to grab only the minimum required\n",
        "memory at the start of the process.\n",
        "\n",
        "    `config.gpu_options.allow_growth = True`"
      ]
    },
    {
      "metadata": {
        "id": "E6bwp7kLfi6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Multiple graphs\n",
        "The recommended approach is to have multiple subgraphs in a single graph.\n",
        "\n",
        "In case\n",
        "you wish to use your own graph instead of the default graph, you can do so with\n",
        "the `tf.graph()` command."
      ]
    },
    {
      "metadata": {
        "id": "cNDbgX7Rfzcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83d469d9-4dce-42dc-ed51-b392106a4383"
      },
      "cell_type": "code",
      "source": [
        "g = tf.Graph()\n",
        "output = 0\n",
        "\n",
        "# linear model\n",
        "with g.as_default():\n",
        "  w = tf.Variable([0.3], tf.float32)\n",
        "  b = tf.Variable([-0.3], tf.float32)\n",
        "  x = tf.placeholder(tf.float32)\n",
        "  y = w*x+b\n",
        "  \n",
        "with tf.Session(graph=g) as tfs:\n",
        "  tf.global_variables_initializer().run()\n",
        "  output = tfs.run(y, {x:[1,2,3,4]})\n",
        "  \n",
        "print('output : ', output)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output :  [0.         0.3        0.6        0.90000004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EdpiAZbcgQ6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TensorBoard\n",
        "Within the context of the running session,\n",
        "* Initialize global variables\n",
        "* create `tf.summary.FileWriter` that would  create the output in the `tflogs` folder with the events from the default graph\n",
        "* fetch the value of node `y`"
      ]
    },
    {
      "metadata": {
        "id": "_a5RRJiujs7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbea15db-ecaf-4fe1-c4e8-f0590f5367a9"
      },
      "cell_type": "code",
      "source": [
        "# Assume Linear Model y = w * x + b\n",
        "# Define model parameters\n",
        "w = tf.Variable([.3], name='w', dtype=tf.float32)\n",
        "b = tf.Variable([-.3], name='b', dtype=tf.float32)\n",
        "# Define model input and output\n",
        "x = tf.placeholder(name='x', dtype=tf.float32)\n",
        "y = w * x + b\n",
        "\n",
        "with tf.Session() as tfs:\n",
        "    tf.global_variables_initializer().run()\n",
        "    writer = tf.summary.FileWriter('tflogs', tfs.graph)\n",
        "    print('run(y,{x:3}) : ', tfs.run(y, feed_dict={x: 3}))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run(y,{x:3}) :  [0.6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "13IYk2RXkVX1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set up TensorBoard in Colab,"
      ]
    },
    {
      "metadata": {
        "id": "wCUd_46RkYfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "98613318-f06f-49c1-c3b6-b237a96ea4b2"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-05 20:36:58--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.75.11, 52.54.84.112, 54.174.228.92, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.75.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-11-05 20:36:59 (35.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fTjv7eylfip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f3f93c7-a207-4e41-de51-e3a2d35b117e"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './tflogs'\n",
        "get_ipython().system_raw(\n",
        "      'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://703196d6.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}