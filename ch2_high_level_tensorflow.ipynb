{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch2_high-level_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/master_tensorflow_keras/blob/master/ch2_high_level_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W-4vGmRhG3mb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "High-level libraries:\n",
        "* TF Estimator - previously TF Learn\n",
        "* TF Slim\n",
        "* TFLearn\n",
        "* PrettyTensor\n",
        "* Sonnet"
      ]
    },
    {
      "metadata": {
        "id": "u8OOsSSeIku3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7UFdQv8HJQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TF Estimator - previously TF Learn\n",
        "makes it simple to create and train models by\n",
        "encapsulating the functionalities for training, evaluating, predicting and exporting.\n",
        "\n",
        "TF Estimator is inspired from Scikit-Learn, providing four main functions on any kind of estimator:\n",
        "* `estimator.fit()`\n",
        "* `estimator.evaluate()`\n",
        "* `estimator.predict()`\n",
        "* `estimator.export()`\n",
        "\n",
        "So far, TensorFlow provides the following pre-built estimators:\n",
        "* `tf.contrib.learn.KMeansClustering`\n",
        "* `tf.contrib.learn.DNNClassifier`\n",
        "* `tf.contrib.learn.DNNRegressor`\n",
        "* `tf.contrib.learn.DNNLinearCombinedRegressor`\n",
        "* `tf.contrib.learn.DNNLinearCombinedClassifier`\n",
        "* `tf.contrib.learn.LinearClassifier`\n",
        "* `tf.contrib.learn.LinearRegressor`\n",
        "* `tf.contrib.learn.LogisticRegressor`\n",
        "\n",
        "##TF Estimator MNIST Example"
      ]
    },
    {
      "metadata": {
        "id": "F12EKk5YHIht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e778f4fa-7287-4d74-c2c5-691cb86893ff"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot=False)\n",
        "\n",
        "x_train = mnist.train.images\n",
        "y_train = mnist.train.labels\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 100\n",
        "n_steps = 1000\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "--2ybJKsTQP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode):\n",
        "    \"\"\" define the model function\"\"\"\n",
        "    espec_op = tf.estimator.EstimatorSpec\n",
        "    # features is a dict as per Estimator specifications\n",
        "    x = features['images']\n",
        "    # define the network\n",
        "    layer_1 = tf.layers.dense(x, 32)\n",
        "    layer_2 = tf.layers.dense(layer_1, 32)\n",
        "    logits = tf.layers.dense(layer_2, n_classes)\n",
        "\n",
        "    # define predicted classes\n",
        "    predicted_classes = tf.argmax(logits, axis=1)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        espec = espec_op(mode, predictions=predicted_classes)\n",
        "    else:\n",
        "        # define loss and optimizer\n",
        "        entropy_op = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
        "        loss_op = tf.reduce_mean(entropy_op(logits=logits,\n",
        "                                            labels=tf.cast(labels, dtype=tf.int32)\n",
        "                                            )\n",
        "                                 )\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
        "\n",
        "        # define accuracy\n",
        "        accuracy_op = tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
        "\n",
        "        espec = espec_op(mode=mode,\n",
        "                         predictions=predicted_classes,\n",
        "                         loss=loss_op,\n",
        "                         train_op=train_op,\n",
        "                         eval_metric_ops={'accuracy': accuracy_op}\n",
        "                         )\n",
        "\n",
        "    return espec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GruR6LVuTaVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "ed3ff5b5-9ada-4763-d9de-126ed5a7774e"
      },
      "cell_type": "code",
      "source": [
        "# create estimator object\n",
        "model = tf.estimator.Estimator(model_fn)\n",
        "\n",
        "# train the model\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': x_train},\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "model.train(train_input_fn, steps=n_steps)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpcxg_xli1\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpcxg_xli1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde4b3ea080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpcxg_xli1/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.7427404, step = 1\n",
            "INFO:tensorflow:global_step/sec: 444.833\n",
            "INFO:tensorflow:loss = 1.4604625, step = 101 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.722\n",
            "INFO:tensorflow:loss = 0.9658919, step = 201 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.806\n",
            "INFO:tensorflow:loss = 0.6103422, step = 301 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.539\n",
            "INFO:tensorflow:loss = 0.5833759, step = 401 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.035\n",
            "INFO:tensorflow:loss = 0.6947203, step = 501 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.757\n",
            "INFO:tensorflow:loss = 0.6505542, step = 601 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.178\n",
            "INFO:tensorflow:loss = 0.51199883, step = 701 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.571\n",
            "INFO:tensorflow:loss = 0.4530944, step = 801 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.803\n",
            "INFO:tensorflow:loss = 0.45031604, step = 901 (0.220 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpcxg_xli1/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.30691352.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7fde4b3eaef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "E9_Ns_yzTcSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "58901b2f-146b-43ae-e13e-185696cc9ee3"
      },
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={'images':x_test},\n",
        "                                                  y=y_test,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  shuffle=False)\n",
        "model.evaluate(eval_input_fn)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-06-04:46:10\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpcxg_xli1/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-06-04:46:10\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8869, global_step = 1000, loss = 0.40368512\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpcxg_xli1/model.ckpt-1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8869, 'global_step': 1000, 'loss': 0.40368512}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "nLBGlZJ3V-GR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is totally fine if you cannot fully understand some of the codes. They will be much more understandable in the next few chapters."
      ]
    },
    {
      "metadata": {
        "id": "sJlUT5B_WdAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TF Slim\n",
        "a lightweight library built on top of TensorFlow core for defining and training mdoels.\n",
        "\n",
        "`tf.contrib.slim`\n",
        "\n",
        "check TF Slim installation:\n",
        "\n",
        "    python3 -c 'import tensorflow.contrib.slim as slim; eval =\n",
        "    slim.evaluation.evaluate_once'"
      ]
    },
    {
      "metadata": {
        "id": "Id4Sc4BuW4MQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TF Slim provides several modules that can be picked and applied independently and mixed\n",
        "with other TensorFlow.\n",
        "\n",
        "TF Slim module | Module description\n",
        "--- | ---\n",
        "arg_scope | Provides a mechanism to apply elements to all graph nodes defined under a scope.\n",
        "layers | Provides several different kinds of layers such as `fully_connected`, `conv2d`, and many more.\n",
        "losses | Provides loss functions for training the optimizer\n",
        "learning | Provides functions for training the models\n",
        "evaluation | Provides evaluation functions\n",
        "metrics | Provides metrics functions to be used for evaluating the models\n",
        "regularizers | Provides functions for creating regularization methods\n",
        "variables | Provides functions for variable creation\n",
        "nets | Provides various pre-built and pre-trained models such as VGG16, InceptionV3, ResNet\n",
        "\n",
        "##TF Slim MNIST Example,"
      ]
    },
    {
      "metadata": {
        "id": "yYIG1S_bWcVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "87b390f0-80c1-412e-8456-c52b636ff309"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.contrib import slim\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "n_classes = 10\n",
        "n_steps = 1000\n",
        "\n",
        "# get the data\n",
        "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot=True)\n",
        "\n",
        "X_train = mnist.train.images\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "Y_train = mnist.train.labels\n",
        "Y_train = tf.convert_to_tensor(Y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s9Hymc2cX7cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mlp(x):\n",
        "  net = slim.fully_connected(x, 32, scope='fc1')\n",
        "  net = slim.dropout(net, 0.5, scope='dropout1')\n",
        "  net = slim.fully_connected(net, 32, scope='fc2')\n",
        "  net = slim.dropout(net, 0.5, scope='dropout2')\n",
        "  net = slim.fully_connected(net, n_classes, activation_fn=None, scope='fc3')\n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "74WbdFqbYy0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "logits = mlp(X_train)\n",
        "\n",
        "# define the loss functions and get the total loss\n",
        "loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=Y_train)\n",
        "total_loss = tf.losses.get_total_loss()\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "train_op = slim.learning.create_train_op(total_loss, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8lLwZpVZS-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "be1d5f9e-ddbc-4785-8e03-69428150fbd5"
      },
      "cell_type": "code",
      "source": [
        "# train model\n",
        "final_loss = slim.learning.train(train_op,\n",
        "                                logdir='./slim_logs',\n",
        "                                number_of_steps=n_steps,\n",
        "                                log_every_n_steps=100)\n",
        "print('final loss={}'.format(final_loss))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "INFO:tensorflow:Saving checkpoint to path ./slim_logs/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "INFO:tensorflow:global step 100: loss = 2.2426 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 200: loss = 2.1616 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 300: loss = 2.0764 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 400: loss = 1.9907 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 500: loss = 1.9062 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 600: loss = 1.8290 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 700: loss = 1.7650 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 800: loss = 1.6980 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 900: loss = 1.6325 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 1000: loss = 1.5830 (0.282 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "final loss=1.5830072164535522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UPuK5mipbB3N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TFLearn\n",
        "`pip3 install tflearn`\n",
        "\n",
        "##Creating the TFlearn Layers\n",
        "1. Input layer\n",
        "\n",
        "    `input_layer = tflearn.input_data(shape=[None, num_inputs])`\n",
        "    \n",
        "2. Further layers\n",
        "    \n",
        "    `layer1 = tflearn.fully_connected(input_layer, 10, activation='relu')`\n",
        "    \n",
        "    `layer2 = tflearn.fully_connected(layer1, 10, activation='relu')`\n",
        "    \n",
        "3. Output layer\n",
        "\n",
        "    `output = tflearn.fully_connected(layer2, n_classes, activation='softmax')`\n",
        "    \n",
        "4. Create the final network from the estimator layer such as `regression`:\n",
        "\n",
        "    `net = tflearn.regression(output,optimizer='adam', metric=tflearn.metrics.Accuracy(), loss='categorical_crossentropy')`"
      ]
    },
    {
      "metadata": {
        "id": "FQfT_f9CdBnN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn core layers\n",
        "In the `tflearn.layers.core` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`input_data` | This layer is used to specify the input layer for the neural network.\n",
        "`fully_connected` | This layer is used to specify a layer where all the neurons are connected to all the neurons in the previous layer.\n",
        "`dropout` | This layer is used to specify the dropout regularization. The input elements are scaled by `1/keep_prob` while keeping the expected sum unchanged.\n",
        "`custom_layer` | This layer is used to specify a custom function to be applied to the input. This class wraps our custom function and presents the function as a layer.\n",
        "`reshape` | This layer reshapes the input into the output of specified shape.\n",
        "`flatten` | This layer converts the input tensor to a 2D tensor.\n",
        "`activation` | This layer applies the specified activation function to the input tensor.\n",
        "`single_unit` | This layer applies the linear function to the inputs.\n",
        "`highway` | This layer implements the fully connected highway function.\n",
        "`one_hot_encoding` | This layer converts the numeric labels to their binary vector one-hot encoded representations.\n",
        "`time_distributed` | This layer applies the specified function to each time step of the input tensor.\n",
        "`multi_target_data` | This layer creates and concatenates multiple placeholders, specifically used when the layers use targets from multiple sources"
      ]
    },
    {
      "metadata": {
        "id": "GC0XrGRBd-3e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn convolutional layers\n",
        "In the `tflearn.layers.conv` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`conv_1d` | This layer applies 1D convolutions to the input data\n",
        "`conv_2d` | This layer applies 2D convolutions to the input data\n",
        "`conv_3d` | This layer applies 3D convolutions to the input data\n",
        "`conv_2d_transpose` | This layer applies transpose of conv2_d to the input data\n",
        "`conv_3d_transpose` | This layer applies transpose of conv3_d to the input data\n",
        "`atrous_conv_2d` | This layer computes a 2-D atrous convolution\n",
        "`grouped_conv_2d` | This layer computes a depth-wise 2-D convolution\n",
        "`max_pool_1d` | This layer computes 1-D max pooling\n",
        "`max_pool_2d` | This layer computes 2D max pooling\n",
        "`avg_pool_1d` | This layer computes 1D average pooling\n",
        "`avg_pool_2d` | This layer computes 2D average pooling\n",
        "`upsample_2d` | This layer applies the row and column wise 2-D repeat operation upscore_layer This layer implements the upscore as specified in http://arxiv.org/abs/1411.4038\n",
        "`global_max_pool` | This layer implements the global max pooling operation\n",
        "`global_avg_pool` | This layer implements the global average pooling operation\n",
        "`residual_block` | This layer implements the residual block to create deep residual networks\n",
        "`residual_bottleneck` | This layer implements the residual bottleneck block for deep residual networks\n",
        "`resnext_block` | This layer implements the ResNeXt block"
      ]
    },
    {
      "metadata": {
        "id": "Zg16O6aQel-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn recurrent layers\n",
        "In the `tflearn.layers.recurrent` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`simple_rnn` | This layer implements the simple recurrent neural network model\n",
        "`bidirectional_rnn` | This layer implements the bi-directional RNN model\n",
        "`lstm` | This layer implements the LSTM model\n",
        "`gru` | This layer implements the GRU model"
      ]
    },
    {
      "metadata": {
        "id": "6kiLPmfre0Xl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn normalization layers\n",
        "In the `tflearn.layers.normalization` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`batch_normalization` | This layer normalizes the output of activations of previous layers for each batch\n",
        "`local_response_normalization` | This layer implements the LR normalization\n",
        "`l2_normalization` | This layer applies the L2 normalization to the input tensors"
      ]
    },
    {
      "metadata": {
        "id": "xJjla00QfG3t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn embedding layers\n",
        "In the `tflearn.layers.embedding_ops` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`embedding` | This layer implements the embedding function for a sequence of integer IDs or floats"
      ]
    },
    {
      "metadata": {
        "id": "ztrw4PQOfUxr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn merge layers\n",
        "In the `tflearn.layers.merge_ops` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`merge_outputs` | This layer merges the list of tensors into a single tensor, generally used to merge the output tensors of the same shape\n",
        "`merge` | This layer merges the list of tensors into a single tensor; you can specify the axis along which the merge needs to be done"
      ]
    },
    {
      "metadata": {
        "id": "lBbJv2PafnYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TFLearn estimator layers\n",
        "In the `tflearn.layers.estimator` module,\n",
        "\n",
        "Layer class | Description\n",
        "--- | ---\n",
        "`regression` | This layer implements the linear or logistic regression\n",
        "\n",
        "For regression, you can also specify the optimizer and the loss and metric functions.\n",
        "\n",
        "For optimizer functions in the `tflearn.optimizers` module,\n",
        "* `SGD`\n",
        "* `RMSprop`\n",
        "* `Adam`\n",
        "* `Momentum`\n",
        "* `AdaGrad`\n",
        "* `Ftrl`\n",
        "* `AdaDelta`\n",
        "* `ProximalAdaGrad`\n",
        "* `Nesterov`\n",
        "\n",
        "or you can create custom optimizer using the base class `tflearn.optimizers.Optimizer`\n",
        "\n",
        "For metric functions in the `tflearnl.metrics` module,\n",
        "* `Accuracy` or `accuracy_op`\n",
        "* `Top_k` or `top_k_op`\n",
        "* `R2` or `r2_op`\n",
        "* `WeightedR2` or `weighted_r2_op`\n",
        "* `binary_accuracy_op`\n",
        "\n",
        "Or custom metrics, `tflearn.metrics.Metric` base class\n",
        "\n",
        "For loss functions in the `tflearn.objectives` module,\n",
        "* `softymax_categorical_crossentropy`\n",
        "* `categorical_crossentropy`\n",
        "* `binary_crossentropy`\n",
        "* `weighted_crossentropy`\n",
        "* `mean_square`\n",
        "* `hinge_loss`\n",
        "* `roc_auc_score`\n",
        "* `weak_cross_entropy_2d`\n",
        "\n",
        "For activation functions in the `tflearn.activations` module,\n",
        "* `linear`\n",
        "* `tanh`\n",
        "* `sigmoid`\n",
        "* `softmax`\n",
        "* `softplus`\n",
        "* `softsign`\n",
        "* `relu`\n",
        "* `relu6`\n",
        "* `leaky_relu`\n",
        "* `prelu`\n",
        "* `elu`\n",
        "* `crelu`\n",
        "* `selu`"
      ]
    },
    {
      "metadata": {
        "id": "bDDPyepShrCj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Creating the TFLearn Model\n",
        "`model = tflearn.DNN(net)`\n",
        "##Types of TFLearn Models\n",
        "* `DNN` model, multilayer perceptron from the network that you have created from the layers\n",
        "* `SequenceGenerator` model, allows you to create a deep neural network that can generate sequences\n",
        "\n",
        "##Training the TFLearn Model\n",
        "`model.fit(X_train, Y_train, n_epoch=n_epochs, batch_size=batch_size, show_metric=True, run_id='dense_model')`\n",
        "##Using the TFLearn Model\n",
        "`score = model.evaluate(X_test, Y_test)`\n",
        "\n",
        "##TFLearn MNIST Example,"
      ]
    },
    {
      "metadata": {
        "id": "BUHc5dBKipJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "5494534e-3180-400e-dd91-3cc8fdfd492e"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tflearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jFVor8WFifow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "38322b10-b18a-41bd-b49b-307eae0b5ec0"
      },
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "import tflearn.datasets.mnist as mnist\n",
        "batch_size = 100\n",
        "n_classes = 10\n",
        "n_epochs = 10\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = mnist.load_data(data_dir=os.path.join('.', 'mnist'), one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading MNIST...\n",
            "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cT2jQr6fijtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7ddebfb3-ff4b-41f0-c674-59835d50e8b1"
      },
      "cell_type": "code",
      "source": [
        "# Build deep neural network\n",
        "input_layer = tflearn.input_data(shape=[None, 784])\n",
        "layer1 = tflearn.fully_connected(input_layer, 10, activation='relu')\n",
        "layer2 = tflearn.fully_connected(layer1, 10, activation='relu')\n",
        "output = tflearn.fully_connected(layer2, n_classes, activation='softmax')\n",
        "\n",
        "net = tflearn.regression(output, \n",
        "                         optimizer='adam', \n",
        "                         metric=tflearn.metrics.Accuracy(),\n",
        "                         loss='categorical_crossentropy'\n",
        "                         )\n",
        "model = tflearn.DNN(net)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x_WnQ7TBi_a1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6e15a3a3-d6cd-4249-c90c-eda455f184f7"
      },
      "cell_type": "code",
      "source": [
        "# Train DNN\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          n_epoch=n_epochs,\n",
        "          batch_size=batch_size,\n",
        "          show_metric=True,\n",
        "          run_id='dense_model')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 5499  | total loss: \u001b[1m\u001b[32m0.37611\u001b[0m\u001b[0m | time: 5.368s\n",
            "| Adam | epoch: 010 | loss: 0.37611 - acc: 0.9101 -- iter: 54900/55000\n",
            "Training Step: 5500  | total loss: \u001b[1m\u001b[32m0.35741\u001b[0m\u001b[0m | time: 5.380s\n",
            "| Adam | epoch: 010 | loss: 0.35741 - acc: 0.9151 -- iter: 55000/55000\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fslSY8AUjNLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cd895a0-4c04-4dc1-a990-72afa0b6cad9"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the DNN\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', score[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xVAjDy-xjyBr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#PrettyTensor\n",
        "provides a thin wrapper on top of TensorFlow.\n",
        "\n",
        "The objects provided by PrettyTensor support a chainable syntax to define neural networks.\n",
        "\n",
        "PrettyTensor offers a very lightweight and extensible interface in the form of a method\n",
        "named `apply()`. Any additional function can be chained to PrettyTensor objects using the\n",
        "`.apply(function, arguments)` method. PrettyTensor will call the `function` and\n",
        "supply the current tensor as the first argument to the `function`.\n",
        "\n",
        "##MNIST example,"
      ]
    },
    {
      "metadata": {
        "id": "_Yu7BqyPkj_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9d870ce2-7dc8-4c0b-df70-b497ee9b2881"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install prettytensor"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prettytensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/59/2a3c18beda72813be70203a76d6cb610fe90f74edcd965d029ebc212be79/prettytensor-0.7.4-py3-none-any.whl (276kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from prettytensor) (1.11.0)\n",
            "Collecting enum34>=1.0.0 (from prettytensor)\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Installing collected packages: enum34, prettytensor\n",
            "Successfully installed enum34-1.1.6 prettytensor-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tNo5j65zlV-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HLGNDVKPkmLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "23980f3f-c99e-4276-c9d7-f8736d4e7da5"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import prettytensor as pt\n",
        "from prettytensor.tutorial import data_utils\n",
        "\n",
        "data_utils.WORK_DIRECTORY = os.path.join('.', 'mnist')\n",
        "\n",
        "# get the data\n",
        "X_train, Y_train = data_utils.mnist(training=True)\n",
        "X_test, Y_test = data_utils.mnist(training=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-08pGEHAkxSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define hyperparameters\n",
        "\n",
        "batch_size = 100     # number of samples that would be used to learn the parameters in a batch\n",
        "n_classes = 10       # number of outputs, i.e. digits 0 to 9\n",
        "n_epochs = 10        # number of ietrations for learning the parameters\n",
        "n_batches = int(X_train.shape[0] / batch_size)\n",
        "n_samples_in_train_batch = 60000 // batch_size\n",
        "n_samples_in_test_batch = 10000 // batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byTV2xWfk47u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define inputs and outputs\n",
        "\n",
        "X = tf.placeholder(tf.float32, [batch_size, 28, 28, 1])\n",
        "Y = tf.placeholder(tf.float32, [batch_size, 10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tfA5Asa3k86A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "\n",
        "pretty_X = pt.wrap(X)\n",
        "\n",
        "model = (pretty_X.flatten().\n",
        "         fully_connected(10).\n",
        "         softmax_classifier(n_classes, labels=Y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwpVP043k_5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define evaluator (metrics), optimizer and training functions\n",
        "\n",
        "evaluator = model.softmax.evaluate_classifier(Y)\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "trainer = pt.apply_optimizer(optimizer, losses=[model.loss])\n",
        "\n",
        "runner = pt.train.Runner()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYGK-C8FmPgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as tfs:\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # shuffle the training data\n",
        "        X_train, Y_train = data_utils.permute_data((X_train, Y_train))\n",
        "\n",
        "        runner.train_model(\n",
        "            trainer,\n",
        "            model.loss,\n",
        "            n_samples_in_train_batch,\n",
        "            feed_vars=(X, Y),\n",
        "            feed_data=pt.train.feed_numpy(batch_size, X_train, Y_train),\n",
        "            print_every=600\n",
        "        )\n",
        "\n",
        "        score = runner.evaluate_model(\n",
        "            evaluator,\n",
        "            n_samples_in_test_batch,\n",
        "            feed_vars=(X, Y),\n",
        "            feed_data=pt.train.feed_numpy(batch_size, X_test, Y_test)\n",
        "        )\n",
        "\n",
        "        print('Accuracy after {} epochs {} \\n'.\n",
        "              format(epoch + 1, score[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hWaHFfXmSZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Sonnet\n",
        "`pip3 install dm-sonnet`\n",
        "\n",
        "The modules are defined as sub-classes of the abstract class `sonnet.AbstractModule`.\n",
        "\n",
        "Modules | Description\n",
        "--- | ---\n",
        "Basic modules | `AddBias, BatchApply, BatchFlatten, BatchReshape, FlattenTrailingDimensions, Linear, MergeDims, SelectInput, SliceByDim, TileByDim,` and `TrainableVariable`\n",
        "Recurrent modules | `DeepRNN, ModelRNN, VanillaRNN, BatchNormLSTM, GRU,` and `LSTM`\n",
        "Recurrent + ConvNet modules | `Conv1DLSTM` and `Conv2DLSTM`\n",
        "ConvNet modules | `Conv1D, Conv2D, Conv3D, Conv1DTranspose, Conv2DTranspose, Conv3DTranspose, DepthWiseConv2D, InPlaneConv2D,` and `SeparableConv2D`\n",
        "ResidualNets | `Residual, ResidualCore,` and `SkipConnectionCore`\n",
        "Others | `BatchNorm, LayerNorm, clip_gradient,` and `scale_gradient`\n",
        "\n",
        "##Sonnet MNIST Example,"
      ]
    },
    {
      "metadata": {
        "id": "fFZWY3hMnRQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMKk1MkknUbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c2739abc-f176-4a14-efec-ae2bee2f99df"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install dm-sonnet"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dm-sonnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/fc/863b22ac6fd5630433fbf7ca5f7212db184953b0f3b9c9f3a030d220c986/dm_sonnet-1.26-py3-none-any.whl (629kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (0.6.1)\n",
            "Collecting contextlib2 (from dm-sonnet)\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (1.11.0)\n",
            "Collecting semantic-version (from dm-sonnet)\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Installing collected packages: contextlib2, semantic-version, dm-sonnet\n",
            "Successfully installed contextlib2-0.5.5 dm-sonnet-1.26 semantic-version-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pb5QvP51nfYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "02d56e75-9569-4235-b5a6-be0919b7f2eb"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow-probability-gpu"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-probability-gpu in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability-gpu) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability-gpu) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-gpu>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability-gpu) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (1.0.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (3.6.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (1.0.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (0.32.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (40.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (3.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu>=1.10.0->tensorflow-probability-gpu) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V7VXIh6UnXd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sonnet as snt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3elpTYtnaPM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST(snt.AbstractModule):\n",
        "\n",
        "    def __init__(self, mnist_part, batch_size, name='MNIST'):\n",
        "\n",
        "        super(MNIST, self).__init__(name=name)\n",
        "\n",
        "        self._X = tf.constant(mnist_part.images, dtype=tf.float32)\n",
        "        self._Y = tf.constant(mnist_part.labels, dtype=tf.float32)\n",
        "        self._batch_size = batch_size\n",
        "        self._M = mnist_part.num_examples\n",
        "\n",
        "    def _build(self):\n",
        "        idx = tf.random_uniform([self._batch_size], 0, self._M, tf.int64)\n",
        "        X = tf.gather(self._X, idx)\n",
        "        Y = tf.gather(self._Y, idx)\n",
        "        return X, Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsyVVJhIn7LZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLP(snt.AbstractModule):\n",
        "    def __init__(self, output_sizes, name='mlp'):\n",
        "        super(MLP, self).__init__(name=name)\n",
        "\n",
        "        self._layers = []\n",
        "\n",
        "        for output_size in output_sizes:\n",
        "            self._layers.append(snt.Linear(output_size=output_size))\n",
        "\n",
        "    def _build(self, X):\n",
        "\n",
        "        # add the input layer\n",
        "        model = tf.sigmoid(self._layers[0](X))\n",
        "\n",
        "        # add hidden layers\n",
        "        for i in range(1, len(self._layers) - 1):\n",
        "            model = tf.sigmoid(self._layers[i](model))\n",
        "\n",
        "        # add output layer\n",
        "        model = tf.nn.softmax(self._layers[len(self._layers) - 1](model))\n",
        "\n",
        "        return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VMKDvyQn84h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_classes = 10\n",
        "n_epochs = 10\n",
        "\n",
        "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'),\n",
        "                                  one_hot=True\n",
        "                                  )\n",
        "train = MNIST(mnist.train, batch_size=batch_size)\n",
        "test = MNIST(mnist.test, batch_size=batch_size)\n",
        "\n",
        "X_train, Y_train = train()\n",
        "X_test, Y_test = test()\n",
        "\n",
        "model = MLP([20, n_classes])\n",
        "\n",
        "Y_train_hat = model(X_train)\n",
        "Y_test_hat = model(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odvNCd06n-uc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss(Y_hat, Y):\n",
        "    return -tf.reduce_sum(Y * tf.log(Y_hat))\n",
        "\n",
        "\n",
        "L_train = loss(Y_train_hat, Y_train)\n",
        "L_test = loss(Y_test_hat, Y_test)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(\n",
        "    learning_rate=0.01).minimize(L_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOuzAV66oAZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as tfs:\n",
        "    tf.global_variables_initializer().run()\n",
        "    for epoch in range(n_epochs):\n",
        "        loss_val, _ = tfs.run((L_train, optimizer))\n",
        "        print('Epoch : {} Training Loss : {}'.format(epoch, loss_val))\n",
        "\n",
        "    loss_val = tfs.run(L_test)\n",
        "    print('Test loss : {}'.format(loss_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xm51ANeBoH34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Summary\n",
        "High-Level Library | Documentation Link | Source Code Link | pip3 install package\n",
        "--- | --- | --- | ---\n",
        "TF Estimator | https://www.tensorflow.org/get_started/estimator | https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/estimator | preinstalled with TensorFlow\n",
        "TF Slim | https://github.com/tensorflow/tensorflow/tree/r1.4/tensorflow/contrib/slim | https://github.com/tensorflow/tensorflow/tree/r1.4/tensorflow/contrib/slim | preinstalled with TensorFlow\n",
        "TFLearn | http://tflearn.org/ | https://github.com/tflearn/tflearn | tflearn\n",
        "PrettyTensor | https://github.com/google/prettytensor/tree/master/docs | https://github.com/google/prettytensor | prettytensor\n",
        "Sonnet | https://deepmind.github.io/sonnet/ | https://github.com/deepmind/sonnet | dm-sonnet"
      ]
    }
  ]
}