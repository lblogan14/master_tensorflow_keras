{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch3_keras_101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/master_tensorflow_keras/blob/master/ch3_keras_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zFGV8Y-qpQwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Installing Keras\n",
        "`pip3 install keras`\n",
        "\n",
        "#Neural Network Models in Keras\n",
        "Neural network models in Keras are defined as the graph of layers. The models in Keras can\n",
        "be created using the sequential or the functional APIs. Both the functional and sequential\n",
        "APIs can be used to build any kind of models.\n",
        "\n",
        "Use the sequential API for simple models\n",
        "built from simple layers and the functional API for complex models involving branches and\n",
        "sharing of layers."
      ]
    },
    {
      "metadata": {
        "id": "PiM52TM4pwO8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Creating the Keras model\n",
        "###Sequential API for creating the Keras model\n",
        "In the sequential API, to create the empty model,\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "Then you can add more layers to this model.\n",
        "\n",
        "ALternatively, you can pass all the layers as a list to the constructor,\n",
        "\n",
        "    model = sequential([Dense(10, input_shape=256,),\n",
        "                        Activation('tanh'),\n",
        "                        Dense(10),\n",
        "                        Activation('softmax')])\n",
        "                        \n",
        "###Functional API for creating the Keras model\n",
        "model is created as an instance of the `Model` class that takes an input and output parameter.\n",
        "\n",
        "    model = Model(inputs=tensor1, outputs=tensor2)\n",
        "    \n",
        "`tensor1` and `tensor2` are either tensors or objects that can be treated like tensors, for example, Keras `layer` objects.\n",
        "\n",
        "If there are more than one input and output tensors, pass as a list,\n",
        "\n",
        "    model = Model(inputs=[i1, i2, i3], outputs=[o1, o2, o3])"
      ]
    },
    {
      "metadata": {
        "id": "vMifMuZirZKf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Keras Layers\n",
        "##Keras core layers\n",
        "Layer name | Description\n",
        "--- | ---\n",
        "`Dense` | This is a simple fully connected neural network layer. This layer produces the output of the following function: **activation((inputs x weights)+bias)** where *activation* refers to the activation function passed to the layer, which is `None` by default.\n",
        "`Activation` | This layer applies the specified activation function to the output. This layer produces the output of the following function: **activation(inputs)** where activation refers to the *activation* function passed to the layer. The following activation functions are available to instantiate this layer: `softmax, elu, selu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid,` and `linear`\n",
        "`Dropout` | This layer applies the dropout regularization to the inputs at a specified dropout rate.\n",
        "`Flatten` | This layer flattens the input, that is, for a three-dimensional input, it flattens and produces a one-dimensional output.\n",
        "`Reshape` | This layer converts the input to the specified shape.\n",
        "`Permute` | This layer reorders the input dimensions as per the specified pattern.\n",
        "`RepeatVector` | This layer repeats the input by the given number of times. Thus, if the input is a 2D tensor of shape (#samples, #features) and the layer is given n times to repeat, then the output will be a 3D tensor of shape (#samples, n, #features).\n",
        "`Lambda` | This layer wraps the provided function as a layer. Thus, the inputs are passed through the custom function provided to produce the outputs. This layer provides ultimate extensibility to Keras users to add their own custom functions as layers.\n",
        "`ActivityRegularization` | This layer applies L1 or L2, or a combination of both kinds of regularization to its inputs. This layer is applied to the output of an activation layer or to the output of  layer that has an activation function.\n",
        "`Masking` | This layer masks or skips those time steps in the input tensor where all the values in the input tensor are equal to the mask value provided as an argument to the layer."
      ]
    },
    {
      "metadata": {
        "id": "Vd6IygYasgqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras convolutional layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`Conv1D` | This layer applies convolutions over a single spatial or temporal dimension to the inputs.\n",
        "`Conv2D` | This layer applies two-dimensional convolutions to the inputs.\n",
        "`SeparableConv2D` | This layer applies a depth-wise spatial convolution on each input channel, followed by a pointwise convolution that mixes together the resulting output channels.\n",
        "`Conv2DTranspose` | This layer reverts the shape of convolutions to the shape of the inputs that produced those convolutions.\n",
        "`Conv3D` | This layer applies three-dimensional convolutions to the inputs.\n",
        "`Cropping1D` | This layer crops the input data along the temporal dimension.\n",
        "`Cropping2D` | This layer crops the input data along the spatial dimensions, such as width and height in the case of an image.\n",
        "`Cropping3D` | This layer crops the input data along the spatio-temporal, that is all three dimensions.\n",
        "`UpSampling1D` | This layer repeats the input data by specified times along the time axis.\n",
        "`UpSampling2D` | This layer repeats the row and column dimensions of the input data by specified times along the two dimensions.\n",
        "`UpSampling3D` | This layer repeats the three dimensions of the input data by specified times along the three dimensions.\n",
        "`ZeroPadding1D` | This layer adds zeros to the beginning and end of the time dimension.\n",
        "`ZeroPadding2D` | This layer adds rows and columns of zeros to the top, bottom, left, or right of a 2D tensor.\n",
        "`ZeroPadding3D` | This layer adds zeros to the three dimensions of a 3D tensor."
      ]
    },
    {
      "metadata": {
        "id": "0D6vMItBtIIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras pooling layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`MaxPooling1D` | This layer implements the max pooling operation for one-dimensional input data.\n",
        "`MaxPooling2D` | This layer implements the max pooling operation for two-dimensional input data.\n",
        "`MaxPooling3D` |  This layer implements the max pooling operation for three-dimensional input data.\n",
        "`AveragePooling1D` | This layer implements the average pooling operation for two-dimensional input data.\n",
        "`AveragePooling2D` | This layer implements the average pooling operation for two-dimensional input data.\n",
        "`AveragePooling3D` | This layer implements the average pooling operation for three-dimensional input data.\n",
        "`GlobalMaxPooling1D` | This layer implements the global max pooling operation for one-dimensional input data.\n",
        "`GlobalAveragePooling1D` | This layer implements the global average pooling operation forone-dimensional input data.\n",
        "`GlobalMaxPooling2D` |  This layer implements the global max pooling operation for two-dimensional input data.\n",
        "`GlobalAveragePooling2D` | This layer implements the global average pooling operation fortwo-dimensional input data."
      ]
    },
    {
      "metadata": {
        "id": "bBS0UNibtikk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras locally-connected layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`LocallyConnected1D` | This layer applies convolutions over a single spatial or temporal dimension to the inputs, by applying a different set of filters at each different patch of the input, thus not sharing the weights.\n",
        "`LocallyConnected2D` | This layer applies convolutions over two dimensions to the inputs, by applying a different set of filters at each different patch of the input, thus not sharing the weights."
      ]
    },
    {
      "metadata": {
        "id": "nyEcW1Z6tyQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras recurrent layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`SimpleRNN` | This layer implements a fully connected recurrent neural network.\n",
        "`GRU` | This layer implements a gated recurrent unit network.\n",
        "`LSTM` | This layer implements a long short-term memory network."
      ]
    },
    {
      "metadata": {
        "id": "AJgPtK1Vt7zx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras embedding layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`Embedding` | This layer takes a 2D tensor of shape (batch_size, sequence_length) consisting of indexes, and produces a tensor consisting of dense vectors of shape (batch_size, sequence_length, output_dim)."
      ]
    },
    {
      "metadata": {
        "id": "uSTaVvPduHA7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras merge layers\n",
        "merge two or more input tensors and produce a single output tensor by\n",
        "applying a specific operation that each layer represents:\n",
        "\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`Add` | This layer computes the element-wise addition of input tensors.\n",
        "`Multiply` | This layer computes the element-wise multiplication of input tensors\n",
        "`Average` | This layer computes the element-wise average of input tensors.\n",
        "`Maximum` | This layer computes the element-wise maximum of input tensors.\n",
        "`Concatenate` | This layer concatenates the input tensors along a specified axis.\n",
        "`Dot` | This layer computes the dot product between samples in two input tensors.\n",
        "`add, multiply, average, maximum, concatenate,`and `dot`| These functions represent the functional interface to the respective merge layers described in this table."
      ]
    },
    {
      "metadata": {
        "id": "RF7w5pYfuhsZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras advanced activation layers\n",
        "Layer Name | Description\n",
        "--- | ---\n",
        "`LeakyReLU` | This layer computes the leaky version of the ReLU activation function.\n",
        "`PReLU` | This layer computes the parametric ReLU activation function.\n",
        "`ELU` | This layer computes the exponential linear unit activation function.\n",
        "`ThresholdedReLU` | This layer computes the thresholded version of the ReLU activation function."
      ]
    },
    {
      "metadata": {
        "id": "oY94T4Zhuy1v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras normalization layers\n",
        "Layer name | Description\n",
        "--- | ---\n",
        "`BatchNormalization` | This layer normalizes the outputs of the previous layer at each batch, such that the output of this layer is approximated to have a mean close to zero and a standard deviation close to 1."
      ]
    },
    {
      "metadata": {
        "id": "0rGaw6ETu7dZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Keras noise layers\n",
        "can be added to the model to prevent overfitting by adding noise; they are also\n",
        "known as regularization layers. These layers operate the same way as\n",
        "the `Dropout()` and `ActivityRegularizer()` layers in the core layers section.\n",
        "\n",
        "Layer name | Description\n",
        "--- | ---\n",
        "`GaussianNoise` | This layer applies additive zero-centered Gaussian noise to the inputs.\n",
        "`GaussianDropout` | This layer applies multiplicative one-centered Gaussian noise to the inputs.\n",
        "`AlphaDropout` | This layer drops a certain percentage of inputs, such that the mean and variance of the outputs after the dropout match closely with the mean and variance of the inputs."
      ]
    },
    {
      "metadata": {
        "id": "B-dQxyGjvWNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Adding Layers to the Keras Model\n",
        "##Sequential API to add layers to the Keras model\n",
        "Use `model.add()` to add layers\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_shape=(256,))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "##Functional API to add layers to the Keras Model\n",
        "    \n",
        "    input = Input(shape=(64,))\n",
        "    hidden = Dense(10)(inputs)\n",
        "    hidden = Activation('tanh')(hidden)\n",
        "    hidden = Dense(10)(hidden)\n",
        "    output = Activation('tanh')(hidden)\n",
        "    model = Model(inputs=input, outputs=output)"
      ]
    },
    {
      "metadata": {
        "id": "p8oWcG8yWVL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Compiling the Keras model\n",
        "The `model.compile()` method has to be called before it can be used for training and prediction after building the network.\n",
        "\n",
        "`compile(self, optimizer, loss, metrics=None, sample_weight_mode=None)`\n",
        "\n",
        "* `optimizer`:\n",
        "  * `SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam`\n",
        "* `loss`:\n",
        "  * `mean_squared_error, mean_absolute_error, mean_absolute_pecentage_error, mean_squared_logarithmic_error, squared_hinge, hinge, categorical_hinge, sparse_categorical_crossentropy, binary_crossentropy, poisson, cosine proximity, binary_accuracy, categorical_accuracy, sparse_categorical_accuracy, top_k_categorical_accuracy, sparse_top_k_categorical_accuracy`\n",
        "* `metrics`"
      ]
    },
    {
      "metadata": {
        "id": "IuMNFgpnXh1f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training the Keras model\n",
        "The `fit` method can be initialized as \n",
        "\n",
        "`fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)`\n",
        "\n",
        "For example, \n",
        "\n",
        "`model.fit(x_data, y_labels)`\n",
        "\n",
        "##Predicting with the Keras model\n",
        "For prediction,\n",
        "\n",
        "`model.prdict()`\n",
        "\n",
        "The `predict` method takes `predict(self, x, batch_size=32, verbose=0)`\n",
        "\n",
        "For evaluation,\n",
        "\n",
        "`model.evaluate()`\n",
        "\n",
        "The `evaluate` method takes `evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)`"
      ]
    },
    {
      "metadata": {
        "id": "koujoLiNdIsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Additional module in Keras\n",
        "* `preprocessing`\n",
        "* `datasets`\n",
        "* `initializers`, provides functions to set initial random weight parameters of layers, such as, `as Zeros, Ones, Constant, RandomNormal, RandomUniform, TruncatedNorma\n",
        "l, VarianceScaling, Orthogonal, Identity, lecun_normal, lecun_unifor\n",
        "m, glorot_normal, glorot_uniform, he_normal, and he_uniform.`\n",
        "* `model`, provides several functions to restore the model architectures and weights, such as `model_from_json, model_from_yaml, and load_model`. Also, `model.to_yaml()` and `model.to_json()`are used to save model architectures.\n",
        "* `application`, provides pre-built and pre-trained models, such as Xception, VGG16, VGG19, ResNet50, Inception V3, InceptionResNetV2, and MobileNet\n",
        "\n",
        "##Keras sequential model example for MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "DW_q71xseYMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c607f742-d25b-4ef3-a830-fc940bbe4931"
      },
      "cell_type": "code",
      "source": [
        "# import the keras modules\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GDxyJcBFenZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54798fab-80b3-4510-8fa1-99c66f775012"
      },
      "cell_type": "code",
      "source": [
        "# define parameters\n",
        "batch_size = 100\n",
        "n_inputs = 28*28\n",
        "n_classes = 10\n",
        "n_epochs = 10\n",
        "\n",
        "# get data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape 28x28 inputs to a row vector of 784 pixels\n",
        "x_train = x_train.reshape(60000, n_inputs)\n",
        "x_test = x_test.reshape(10000, n_inputs)\n",
        "\n",
        "# convert input values to float32\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "# normalization\n",
        "x_train /= 255.\n",
        "x_test /= 255.\n",
        "\n",
        "# convert output to one-hot\n",
        "y_train = utils.to_categorical(y_train, n_classes)\n",
        "y_test = utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PRVqq7zDfhx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d9e7a24d-6819-4ac6-a299-3928ae37351c"
      },
      "cell_type": "code",
      "source": [
        "# sequential mode\n",
        "model = Sequential()\n",
        "# the first layer has to specify the dimensions of the input vector\n",
        "model.add(Dense(units=128, activation='sigmoid', input_shape=(n_inputs,)))\n",
        "# add dropout layer for preventing overfitting\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=128, activation='sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "# output layer can only have the neurons equal to the number of outputs\n",
        "model.add(Dense(units=n_classes, activation='softmax'))\n",
        "\n",
        "# print the summary\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Tz39njogQ-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "4bfe26f8-b391-4233-d453-9d45f6de1a40"
      },
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=SGD(),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 2.2993 - acc: 0.1318\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.2341 - acc: 0.1963\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.1478 - acc: 0.2928\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.0137 - acc: 0.3973\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 1.8122 - acc: 0.4919\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.5712 - acc: 0.5690\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.3488 - acc: 0.6276\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.1687 - acc: 0.6734\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 1.0382 - acc: 0.7060\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.9354 - acc: 0.7304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6d94733c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "KeKppBn3gp_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f158df59-eb3f-4413-d33e-923a84b4f910"
      },
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print('\\n loss:', scores[0])\n",
        "print('\\n accuracy:', scores[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " loss: 0.8117022010803223\n",
            "\n",
            " accuracy: 0.802\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}